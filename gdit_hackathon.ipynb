{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c6b0541",
   "metadata": {},
   "source": [
    "# Welcome to the GDIT Hackathon!\n",
    "\n",
    "We’re thrilled to have you join us for today's event! This hackathon is designed to give you hands-on experience with the SeekrFlow platform, explore practical AI-driven solutions, and collaborate creatively to tackle real-world challenges.\n",
    "\n",
    "\n",
    "\n",
    "### What You’ll Learn\n",
    "\n",
    "Throughout this hackathon, you'll be introduced to:\n",
    "\n",
    "* **SeekrFlow Basics:** How to interact with AI agents to answer business questions.\n",
    "* **Agentic Workflows:** Leveraging pre-built agents to solve specific tasks.\n",
    "* **Vector Search and Retrieval:** Finding relevant information quickly and effectively.\n",
    "* **Understanding Predictive Insights:** Interpreting outputs from predictive models provided to you.\n",
    "* **Practical Application:** Applying these tools directly to real-world GDIT challenges.\n",
    "\n",
    "\n",
    "\n",
    "### How to Use This Notebook\n",
    "\n",
    "This notebook is your interactive guide for the day. Here's how you can make the most of it:\n",
    "\n",
    "* **Follow Step-by-Step:** Each section is clearly labeled, guiding you from introduction to practical implementation.\n",
    "* **Interactive Exercises:** You'll be given clear prompts where you can enter your own inputs or run provided examples.\n",
    "* **Understand the Concepts:** Explanations are provided to help you understand what’s happening behind the scenes.\n",
    "* **Reference Material:** Quick reference sections are included to help you recall key concepts and code snippets throughout the hackathon.\n",
    "\n",
    "\n",
    "\n",
    "### Goals and Outcomes\n",
    "\n",
    "By the end of the hackathon, you’ll be able to:\n",
    "\n",
    "* Confidently use SeekrFlow agents to answer business-critical questions.\n",
    "* Understand how AI-driven solutions can automate and streamline your workflow.\n",
    "* Demonstrate your team's innovative solution to the provided challenge.\n",
    "* Engage with your peers and exchange insights and ideas.\n",
    "\n",
    "\n",
    "\n",
    "### Let's Get Started!\n",
    "\n",
    "Dive into the notebook, ask questions, collaborate, and most importantly, enjoy the experience. We’re excited to see the innovative solutions your team develops today!\n",
    "\n",
    "Happy hacking!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab520805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seekrai import SeekrFlow\n",
    "import os, getpass\n",
    "os.environ[\"SEEKR_API_KEY\"] = getpass.getpass(\"Enter API key:\")\n",
    "\n",
    "# Initialize client\n",
    "client = SeekrFlow(api_key=os.environ[\"SEEKR_API_KEY\"])\n",
    "BASE_URL = \"https://flow.seekr.com/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdedaa74",
   "metadata": {},
   "source": [
    "# Vector Databases & Embeddings: What’s Happening Here\n",
    "\n",
    "Before we load any data, we need a place to store our “embeddings” — dense numerical representations of each record that capture its meaning and relationships. That’s exactly what a **vector database** is for.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. What Is an Embedding?  \n",
    "- An **embedding** is a fixed-length numeric vector (e.g. 768 floats) generated by a model (like Mistral).  \n",
    "- It encodes the semantic essence of a piece of text — in our case, a string of water‐quality features.  \n",
    "- Similar records produce embeddings that sit close together in high-dimensional space.\n",
    "\n",
    "\n",
    "### 2. Why Use a Vector Database?  \n",
    "- We want to ask: “Which past record is most like my new sensor reading?”  \n",
    "- A vector database indexes all embeddings and lets us do **nearest-neighbor search** quickly.  \n",
    "- Behind the scenes it’s optimized for large-scale similarity queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seekrai import Client\n",
    "\n",
    "# Create vector database\n",
    "vector_db = client.vector_database.create(\n",
    "    name=\"refugee\",\n",
    "    model=\"intfloat/e5-mistral-7b-instruct\",\n",
    "    description=\"GDIT Hackathon 2025 - Refugee Asylum\",\n",
    ")\n",
    "db_id = vector_db.id\n",
    "print(f\"✅ Created Vector DB '{vector_db.name}' (ID: {db_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c3f5d",
   "metadata": {},
   "source": [
    "# Locating & Uploading Your Challenge Data\n",
    "\n",
    "Each hackathon track comes with its own set of pre-generated data. Before you upload them into SeekrFlow, you need to point the script at the correct directory.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Identify Your Challenge Folder\n",
    "\n",
    "| Use Case                                | Directory                           |\n",
    "|-----------------------------------------|-------------------------------------|\n",
    "| **Medicare/Medicaid Work Requirements** | `medicare/medicare_md`               |\n",
    "| **Asylum-Interview Similarity**         | `refugee/refugee_md`      |\n",
    "| **USPS Shipping Fraud Investigation**   | `usps/`          |\n",
    "| **Water Quality Sensor Alerts**         | `water/`          |\n",
    "| **Commander's Intent/OPORDER**          | `defense/`          |\n",
    "\n",
    "*(If you renamed or moved the folders, adjust the path accordingly.)*\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Update the `base_dir` Variable\n",
    "\n",
    "In the code cell below, replace the default `base_dir` value with the directory for **your** use case. For example, if you’re working on water quality:\n",
    "\n",
    "```python\n",
    "# Point to your track’s Markdown folder\n",
    "base_dir = \"refugee/refugee_md\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the directory containing your data\n",
    "base_dir = \"refugee/refugee_md/\"\n",
    "\n",
    "file_ids = []\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(\".md\"):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            resp = client.files.upload(file_path, purpose=\"alignment\")\n",
    "            file_ids.append(resp.id)\n",
    "            print(f\"Uploaded {filename} → {resp.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb4c5f",
   "metadata": {},
   "source": [
    "# What’s Happening in the Ingestion Step\n",
    "\n",
    "Once you’ve uploaded your Markdown files into SeekrFlow, the next step is to **ingest** them into your vector database. This is where your raw text is broken into “chunks,” embedded, and stored for fast similarity search. The following parameters are configurable.\n",
    "\n",
    "### 1. `token_count=512` (Chunk Size)\n",
    "Determines the approximate number of tokens (words/subwords) per chunk.\n",
    "\n",
    "**Impacts:**  \n",
    "- **Larger chunk** (e.g. 1024+):  \n",
    "  - Pros: more context in each retrieval  \n",
    "  - Cons: slower embedding calls, higher memory usage, fewer chunks overall  \n",
    "- **Smaller chunk** (e.g. 256):  \n",
    "  - Pros: faster ingestion, more fine-grained retrieval  \n",
    "  - Cons: risk of losing cross-sentence context  \n",
    "\n",
    "**Best practice:**  \n",
    "Start with **512–768** tokens per chunk for general documents. Tune up or down based on average document length and retrieval quality.\n",
    "\n",
    "\n",
    "\n",
    "### 2. `overlap_tokens=50` (Chunk Overlap)\n",
    "Specifies how many tokens to repeat at the start of the next chunk.\n",
    "\n",
    "**Why overlap?**  \n",
    "- Prevents important context from falling in the “gap” between adjacent chunks  \n",
    "- Improves retrieval accuracy for queries that span chunk boundaries  \n",
    "\n",
    "**Trade-offs:**  \n",
    "- **More overlap** (e.g. 100–150):  \n",
    "  - Better context continuity  \n",
    "  - More storage & compute (duplicates between chunks)  \n",
    "- **Less overlap** (e.g. 20–30):  \n",
    "  - Leaner storage, faster ingestion  \n",
    "  - Higher risk of missing cross-boundary associations  \n",
    "\n",
    "**Rule of thumb:**  \n",
    "Overlap of **10%–20%** of your `token_count` is a good starting point (e.g. 50–100 tokens for 512).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ac737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick off ingestion with the collected IDs\n",
    "ingest_job = client.vector_database.create_ingestion_job(\n",
    "    database_id=db_id,\n",
    "    files=file_ids,\n",
    "    method=\"best\",\n",
    "    token_count=512,\n",
    "    overlap_tokens=50,\n",
    ")\n",
    "print(f\"⏳ Ingestion job submitted: {ingest_job.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor ingestion job\n",
    "import time\n",
    "\n",
    "timeout = 300  # 5 minutes timeout\n",
    "interval = 5   # Check every 5 seconds\n",
    "\n",
    "while True:\n",
    "    job_status = client.vector_database.retrieve_ingestion_job(db_id, ingest_job.id)\n",
    "    status = job_status.status\n",
    "    print(f\"Ingestion job status: {status}\")\n",
    "\n",
    "    if status == \"completed\":\n",
    "        print(\"Vector database ready!\")\n",
    "        break\n",
    "    elif status == \"failed\":\n",
    "        error = getattr(job_status, \"error_message\", \"Unknown error\")\n",
    "        print(f\"Ingestion job failed: {error}\")\n",
    "        break\n",
    "\n",
    "    time.sleep(interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bde5ac",
   "metadata": {},
   "source": [
    "# General Guide: Building Effective SeekrFlow Agents\n",
    "\n",
    "Use this as a blueprint for creating any SeekrFlow agent—regardless of challenge—by focusing on tool setup, prompt design, model choice, and iteration best practices.\n",
    "\n",
    "\n",
    "\n",
    "## 1. Define Your Tools Clearly  \n",
    "Every agent needs “tools” to reach outside the LLM’s knowledge.  \n",
    "- **Name & Description**  \n",
    "  Give each tool a human‐readable label and a concise description  \n",
    "  (e.g. “VectorSearch: lookup similar records in the water_quality index”).  \n",
    "- **Configuration Parameters**  \n",
    "  - For a vector search tool: the vector-DB ID, chunking or index settings, etc.  \n",
    "  - For a web search tool: target domains or recency filters.  \n",
    "- **Best Practices**  \n",
    "  - One tool → one responsibility.  \n",
    "  - Keep descriptions < 12 words.  \n",
    "  - Use consistent naming conventions across agents.\n",
    "\n",
    "\n",
    "\n",
    "## 2. Craft Step-by-Step Agent Instructions  \n",
    "Your prompt is the single most powerful lever for steering behavior.  \n",
    "- **Break Down the Workflow**  \n",
    "  1. **Receive** the user input in its expected format (JSON, pipe string, etc.).  \n",
    "  2. **Call** the right tool with that raw input.  \n",
    "  3. **Extract** the needed field from the tool result (e.g. `metadata.event_type`).  \n",
    "  4. **Generate** the final user‐facing output (report, plan, recommendation).  \n",
    "- **Constrain Output**  \n",
    "  - Specify exactly what to return (e.g. “Output only the maintenance plan.”).  \n",
    "  - Discourage extra commentary or restating the prompt.  \n",
    "- **Tone & Style**  \n",
    "  - Define audience (business stakeholders vs. technical users).  \n",
    "  - Use bullet lists or short paragraphs for readability.  \n",
    "- **Troubleshooting Tips**  \n",
    "  - If the agent hallucinates or misses a tool call, add or refine explicit tool‐calling instructions.  \n",
    "  - Numbered steps help enforce the order of operations.\n",
    "\n",
    "\n",
    "\n",
    "## 3. Choose the Right Model  \n",
    "Selecting a model impacts speed, cost, and fidelity:  \n",
    "- **Instruction-tuned vs. Base**  \n",
    "  - Instruct models excel at following detailed prompts and formatting outputs.  \n",
    "- **Size Trade-offs**  \n",
    "  - Smaller (< 4B) for very low-latency tasks or tight compute budgets.  \n",
    "  - Mid-range (8B) for balanced speed and reasoning.  \n",
    "  - Large (> 13B) for the most complex, multi-step logic.  \n",
    "- **When to Switch**  \n",
    "  - Increase size if the agent truncates steps or produces inconsistent outputs.  \n",
    "  - Downgrade if simple tasks run slowly and network latency is a concern.\n",
    "\n",
    "\n",
    "\n",
    "## 4. Assemble & Register Your Agent  \n",
    "Use the SDK or UI to bring everything together:  \n",
    "1. **Initialize** your client with a secure API key.  \n",
    "2. **Register** each tool with its configuration.  \n",
    "3. **Compose** a `CreateAgentRequest` (or UI equivalent) including:\n",
    "   - Agent **name**  \n",
    "   - **instructions** text  \n",
    "   - **model_id**  \n",
    "   - **tools** list  \n",
    "4. **Create** the agent and note its ID for interactive queries.\n",
    "\n",
    "\n",
    "\n",
    "## 5. Validate & Iterate  \n",
    "Before tackling full use cases, run quick sanity checks:  \n",
    "- **Smoke Test**  \n",
    "  - Send a representative sample input; confirm the correct tool is called.  \n",
    "  - Verify the agent returns only the desired output format.  \n",
    "- **Refine Prompt**  \n",
    "  - Tighten or reorder steps if the agent wanders off.  \n",
    "  - Add output examples or templates for clarity (few-shot style).  \n",
    "- **Log & Compare**  \n",
    "  - Keep versions of your instructions and record outcomes.  \n",
    "  - Share change summaries with your team to converge on best phrasing.\n",
    "\n",
    "\n",
    "\n",
    "### 🚀 Final Tips  \n",
    "- **Clarity over cleverness:** explicit > implicit.  \n",
    "- **Modular design:** separate tools, prompts, and data so you can swap pieces easily.  \n",
    "- **Collaborate early:** peer-review prompts and tool configs before hackathon demos.  \n",
    "\n",
    "Follow this framework on any challenge—Medicare eligibility, shipping fraud, water quality—and you’ll build agents that are reliable, transparent, and ready for real‐world impact.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6670f",
   "metadata": {},
   "source": [
    "<div class=\"card\">\n",
    "\n",
    "## 🛠️ **Understanding Your Agent's Tools**\n",
    "\n",
    "Your SeekrFlow agent will use specialized tools—**FileSearch** and **WebSearch**—to access and retrieve external information. Here’s how each tool works in practice, helping you set proper expectations and craft effective prompts.\n",
    "\n",
    "\n",
    "\n",
    "### 📂 **FileSearch Tool**\n",
    "\n",
    "**Purpose:**  \n",
    "Searches a pre-loaded vector database containing structured documents and data provided specifically for the hackathon.\n",
    "\n",
    "**What Happens Under the Hood:**  \n",
    "- **Similarity Search:** Your query is embedded into a numeric format, and the tool finds the most similar records in the database.\n",
    "- **Returned Results:** Typically include:\n",
    "  - Relevant text snippets or records from the stored documents.\n",
    "  - Associated metadata (e.g., event types, IDs, timestamps).\n",
    "\n",
    "**Best Practices:**  \n",
    "- Queries should clearly reference identifiable fields or terms from your data.\n",
    "- Ideal for specific, structured lookups—like member profiles, historical events, sensor readings, or labeled classifications.\n",
    "\n",
    "\n",
    "\n",
    "### 🌐 **WebSearch Tool**\n",
    "\n",
    "**Purpose:**  \n",
    "Performs a real-time search using BraveSearch to retrieve the latest, publicly available web information.\n",
    "\n",
    "**How WebSearch Operates:**  \n",
    "  - Sends your query to BraveSearch.\n",
    "  - Retrieves a set of metadata-rich results, including **page title**, **snippet (~120 characters)**, and **URL**.\n",
    "  - **Note:** No full page content returned at this step.\n",
    "  \n",
    "**Best Practices:**  \n",
    "- Ideal for up-to-date facts, regulations, guidelines, or public records.\n",
    "- Craft specific queries to get precise, relevant snippets.\n",
    "- Be aware of the snippet limitations; use concise, clear wording to improve relevance.\n",
    "\n",
    "\n",
    "\n",
    "### 📌 **Key Takeaways for Using Tools**\n",
    "\n",
    "- **FileSearch** is great for targeted, structured lookups using your provided datasets.\n",
    "- **WebSearch** excels at finding current external information quickly but returns limited initial context (titles, URLs, short snippets).\n",
    "\n",
    "By understanding these behaviors, you can craft prompts that help your agent retrieve exactly the insights you need for the challenge.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f92059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seekrai import SeekrFlow\n",
    "from seekrai.types import CreateAgentRequest, FileSearch, FileSearchEnv, WebSearch, WebSearchEnv\n",
    "\n",
    "# Vector DB that holds historical asylum-seeker interview chunks\n",
    "vector_search_tool = FileSearch(\n",
    "    tool_env=FileSearchEnv(\n",
    "        file_search_index=db_id,\n",
    "        document_tool_desc=\"Historical database of asylum-seeker interviews\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Optional external fact-checking (e.g., news / NGO / gov sites from the past week)\n",
    "web_search_tool = WebSearch(\n",
    "    tool_env=WebSearchEnv()\n",
    ")\n",
    "\n",
    "agent_req = CreateAgentRequest(\n",
    "    name=\"test\",\n",
    "    instructions=\"\"\"\n",
    "\n",
    "You are **test**, an expert assistant that can:\n",
    "\n",
    "\n",
    "\"\"\".strip(),\n",
    "    model_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    tools=[vector_search_tool, web_search_tool]\n",
    ")\n",
    "\n",
    "agent = client.agents.create(agent_req)\n",
    "print(\"Created agent:\", agent.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64974123",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.agents.retrieve(agent_id=agent.id)\n",
    "status = client.agents.retrieve(agent_id=agent.id).status\n",
    "print(status)\n",
    "print(agent.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a6db8",
   "metadata": {},
   "source": [
    "## 🧵 Understanding Threads in SeekrFlow\n",
    "\n",
    "Even though you’ll be interacting with agents via the Sandbox UI during the hackathon, it’s helpful to know how the underlying “thread” concept works in code. A **thread** is simply the container for a single conversation with an agent—much like a chat room or ticket—and it keeps all your messages, tool calls, and responses neatly grouped.\n",
    "\n",
    "\n",
    "\n",
    "### 1. What Is a Thread?  \n",
    "- A thread represents one discrete dialogue or task instance.  \n",
    "- It stores all user messages, assistant messages, and intermediate tool outputs.  \n",
    "- You can have multiple concurrent threads against the same agent (e.g. testing different sensor inputs in parallel).\n",
    "\n",
    "\n",
    "\n",
    "### 2. Core Thread Operations\n",
    "\n",
    "| Step                           | Purpose                                                                 |\n",
    "|--------------------------------|-------------------------------------------------------------------------|\n",
    "| **Create a thread**            | `client.agents.threads.create()` → returns a new `thread.id`.           |\n",
    "| **Post a user message**        | `create_message(thread_id, role=\"user\", content=...)`                  |\n",
    "| **Launch the agent run**       | `client.agents.runs.run(agent_id, thread_id, stream=False)`            |\n",
    "| **Fetch assistant replies**    | `client.agents.threads.list_messages(thread_id)` and filter `role==\"assistant\"` |\n",
    "\n",
    "### 3. Why Threads Matter\n",
    "\n",
    "- **Stateless Agents**  \n",
    "  Each run is isolated to its thread; you won’t accidentally mix up inputs or outputs from different tests.\n",
    "\n",
    "- **Audit Trail**  \n",
    "  All messages, tool calls, and responses are preserved—useful for debugging or compliance.\n",
    "\n",
    "- **Parallel Testing**  \n",
    "  Spin up multiple threads to compare different prompts, tool configurations, or input records side-by-side.\n",
    "\n",
    "\n",
    "\n",
    "### 4. Hackathon Takeaway\n",
    "\n",
    "In the UI you’ll see a familiar chat interface; under the covers, SeekrFlow is managing these threads via API. Knowing how threads work will help you:\n",
    "\n",
    "- Interpret logs and debug unexpected responses.  \n",
    "- Automate batch testing in code if you choose to extend beyond the UI.  \n",
    "- Understand how context is preserved across multi-step workflows.\n",
    "- **Update the `content` field** when posting your user message to test different inputs against your agent and observe how it responds.\n",
    "\n",
    "Now you’re armed with the “thread” concept—let’s keep iterating on those agents!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc145f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seekrai import SeekrFlow\n",
    "\n",
    "# Spin up an empty thread\n",
    "thread = client.agents.threads.create()\n",
    "print(\"New thread:\", thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f34c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a. Post your user question\n",
    "user_msg = client.agents.threads.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=(\n",
    "        \"I am interested in the Zone-1 water quality. How many contamination events do we have??\" \n",
    "    )\n",
    ")\n",
    "print(\"✉️ User message posted:\", user_msg.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abba683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5b. Kick off the run (no streaming)\n",
    "run_resp = client.agents.runs.run(\n",
    "    agent_id=agent.id,\n",
    "    thread_id=thread.id,\n",
    "    stream=False\n",
    ")\n",
    "print(\"▶️ Run started, run_id =\", run_resp.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c. Fetch the assistant’s reply once it’s done\n",
    "msgs = client.agents.threads.list_messages(thread.id)\n",
    "assistant_replies = [m for m in msgs if m.role == \"assistant\"]\n",
    "if assistant_replies:\n",
    "    print(\"🤖 Agent reply:\\n\", assistant_replies[-1].content)\n",
    "else:\n",
    "    print(\"⚠️ No reply found yet – try polling again in a few seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ac012",
   "metadata": {},
   "source": [
    "# 🚀 Launch & Interact with Your Agent in the SeekrFlow UI\n",
    "\n",
    "1. Open your browser and go to **https://apps.seekr.com**  \n",
    "2. Enter the credentials provided by your administrator.  \n",
    "3. From the top‐left menu, choose **SeekrFlow**.  \n",
    "4. In the SeekrFlow home screen, click on **Agents Sandbox (Beta)**.  \n",
    "5. In the “Select Agent” dropdown, find and choose the name of the agent you just created (e.g. “v5 Water Quality” or your custom agent name).  \n",
    "6. Start typing your test prompts in the chat window and hit **Send** to see your agent in action!  \n",
    "\n",
    "# Happy hacking—and may your agents be ever responsive!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c815fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
